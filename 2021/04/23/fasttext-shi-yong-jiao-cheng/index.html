<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="fasttext使用教程, 浩的博客">
    <meta name="description" content="第一章:fasttext工具的使用1.1 认识fasttext工具
学习目标
了解fasttext工具的作用.
了解fasttext工具的优势及其原因.
掌握fasttext的安装方法.





作为NLP工程领域常用的工具包, fast">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>fasttext使用教程 | 浩的博客</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
        code[class*="language-"], pre[class*="language-"] {
            white-space: pre !important;
        }
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    
<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="浩的博客" type="application/atom+xml">
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container1">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    <!--
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    -->
                    <span class="logo-span">浩的博客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right nav-menu">
    
    <li class="hide-on-med-and-down nav-item" >
		
					  <a href="/" class="waves-effect waves-light">
						
						<i class="fa fa-home"></i>
						
						<span>首页</span>
					</a>
          
        </li>
    
    <li class="hide-on-med-and-down nav-item" >
		
					  <a href="/tags" class="waves-effect waves-light">
						
						<i class="fa fa-tags"></i>
						
						<span>标签</span>
					</a>
          
        </li>
    
    <li class="hide-on-med-and-down nav-item" >
		
					  <a href="/categories" class="waves-effect waves-light">
						
						<i class="fa fa-bookmark"></i>
						
						<span>分类</span>
					</a>
          
        </li>
    
    <li class="hide-on-med-and-down nav-item" >
		
					  <a href="/archives" class="waves-effect waves-light">
						
						<i class="fa fa-archive"></i>
						
						<span>归档</span>
					</a>
          
        </li>
    
    <li class="hide-on-med-and-down nav-item" >
		
					  <a href="/about" class="waves-effect waves-light">
						
						<i class="fa fa-user-circle-o"></i>
						
						<span>关于</span>
					</a>
          
        </li>
    
    <li class="hide-on-med-and-down nav-item" >
		
					  <a href="/friends" class="waves-effect waves-light">
						
						<i class="fa fa-address-book"></i>
						
						<span>友情链接</span>
					</a>
          
        </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">浩的博客</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
<li class="m-nav-item">
			
				<a href="/" class="waves-effect waves-light">
					
					<i class="fa fa-fw fa-home"></i>
					
					首页
				</a>
          
        </li>
        
<li class="m-nav-item">
			
				<a href="/tags" class="waves-effect waves-light">
					
					<i class="fa fa-fw fa-tags"></i>
					
					标签
				</a>
          
        </li>
        
<li class="m-nav-item">
			
				<a href="/categories" class="waves-effect waves-light">
					
					<i class="fa fa-fw fa-bookmark"></i>
					
					分类
				</a>
          
        </li>
        
<li class="m-nav-item">
			
				<a href="/archives" class="waves-effect waves-light">
					
					<i class="fa fa-fw fa-archive"></i>
					
					归档
				</a>
          
        </li>
        
<li class="m-nav-item">
			
				<a href="/about" class="waves-effect waves-light">
					
					<i class="fa fa-fw fa-user-circle-o"></i>
					
					关于
				</a>
          
        </li>
        
<li class="m-nav-item">
			
				<a href="/friends" class="waves-effect waves-light">
					
					<i class="fa fa-fw fa-address-book"></i>
					
					友情链接
				</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/x-hao" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/x-hao" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/4.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        fasttext使用教程
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/nlp/" target="_blank">
                                <span class="chip bg-color">nlp</span>
                            </a>
                        
                            <a href="/tags/fasttext/" target="_blank">
                                <span class="chip bg-color">fasttext</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/nlp/" class="post-category" target="_blank">
                                nlp
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-04-23
                </div>

                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="第一章-fasttext工具的使用"><a href="#第一章-fasttext工具的使用" class="headerlink" title="第一章:fasttext工具的使用"></a>第一章:fasttext工具的使用</h1><h2 id="1-1-认识fasttext工具"><a href="#1-1-认识fasttext工具" class="headerlink" title="1.1 认识fasttext工具"></a>1.1 认识fasttext工具</h2><hr>
<h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul>
<li>了解fasttext工具的作用.</li>
<li>了解fasttext工具的优势及其原因.</li>
<li>掌握fasttext的安装方法.</li>
</ul>
<hr>
<p><img src="/2021/04/23/fasttext-shi-yong-jiao-cheng/fasttext-logo-color-web.png" alt="img"></p>
<hr>
<ul>
<li>作为NLP工程领域常用的工具包, fasttext有两大作用:<ul>
<li>进行文本分类</li>
<li>训练词向量</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>fasttext工具包的优势:<ul>
<li>正如它的名字, 在保持较高精度的情况下, 快速的进行训练和预测是fasttext的最大优势.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>fasttext优势的原因:<ul>
<li>fasttext工具包中内含的fasttext模型具有十分简单的网络结构.</li>
<li>使用fasttext模型训练词向量时使用层次softmax结构, 来提升超多类别下的模型性能.</li>
<li>由于fasttext模型过于简单无法捕捉词序特征, 因此会进行n-gram特征提取以弥补模型缺陷提升精度.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>fasttext的安装:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">$ git clone https://github.com/facebookresearch/fastText.git
$ cd fastText
# 使用pip安装python中的fasttext工具包
$ sudo pip install .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>验证安装:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">Python 3.7.3 (default, Mar 27 2019, 22:11:17)
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import fasttext
&gt;&gt;&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h2 id="1-2-进行文本分类"><a href="#1-2-进行文本分类" class="headerlink" title="1.2 进行文本分类"></a>1.2 进行文本分类</h2><hr>
<h3 id="学习目标-1"><a href="#学习目标-1" class="headerlink" title="学习目标"></a>学习目标</h3><ul>
<li>了解什么是文本分类及其种类.</li>
<li>掌握fasttext工具进行文本分类的过程.</li>
</ul>
<hr>
<h3 id="什么是文本分类"><a href="#什么是文本分类" class="headerlink" title="什么是文本分类"></a>什么是文本分类</h3><ul>
<li>文本分类的是将文档（例如电子邮件，帖子，文本消息，产品评论等）分配给一个或多个类别. 当今文本分类的实现多是使用机器学习方法从训练数据中提取分类规则以进行分类, 因此构建文本分类器需要带标签的数据.</li>
</ul>
<hr>
<h3 id="文本分类的种类"><a href="#文本分类的种类" class="headerlink" title="文本分类的种类"></a>文本分类的种类</h3><ul>
<li>二分类:<ul>
<li>文本被分类两个类别中, 往往这两个类别是对立面, 比如: 判断一句评论是好评还是差评.</li>
</ul>
</li>
<li>单标签多分类:<ul>
<li>文本被分入到多个类别中, 且每条文本只能属于某一个类别(即被打上某一个标签), 比如: 输入一个人名, 判断它是来自哪个国家的人名.</li>
</ul>
</li>
<li>多标签多分类:<ul>
<li>文本被分人到多个类别中, 但每条文本可以属于多个类别(即被打上多个标签), 比如: 输入一段描述, 判断可能是和哪些兴趣爱好有关, 一段描述中可能即讨论了美食, 又太讨论了游戏爱好.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="使用fasttext工具进行文本分类的过程"><a href="#使用fasttext工具进行文本分类的过程" class="headerlink" title="使用fasttext工具进行文本分类的过程"></a>使用fasttext工具进行文本分类的过程</h3><ul>
<li>第一步: 获取数据</li>
<li>第二步: 训练集与验证集的划分</li>
<li>第三步: 训练模型</li>
<li>第四步: 使用模型进行预测并评估</li>
<li>第五步: 模型调优</li>
<li>第六步: 模型保存与重加载</li>
</ul>
<hr>
<h4 id="第一步-获取数据"><a href="#第一步-获取数据" class="headerlink" title="第一步: 获取数据"></a>第一步: 获取数据</h4><pre class="line-numbers language-none"><code class="language-none"># 获取烹饪相关的数据集, 它是由facebook AI实验室提供的演示数据集
$ wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz &amp;&amp; tar xvzf cooking.stackexchange.tar.gz
# 查看数据的前10条
$ head cooking.stackexchange.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-none"><code class="language-none">__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?
__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments
__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?
__label__restaurant Michelin Three Star Restaurant; but if the chef is not there
__label__knife-skills __label__dicing Without knife skills, how can I quickly and accurately dice vegetables?
__label__storage-method __label__equipment __label__bread What's the purpose of a bread box?
__label__baking __label__food-safety __label__substitutions __label__peanuts how to seperate peanut oil from roasted peanuts at home?
__label__chocolate American equivalent for British chocolate terms
__label__baking __label__oven __label__convection Fan bake vs bake
__label__sauce __label__storage-lifetime __label__acidity __label__mayonnaise Regulation and balancing of readymade packed mayonnaise and other sauces<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<ul>
<li>数据说明:<ul>
<li>cooking.stackexchange.txt中的每一行都包含一个标签列表，后跟相应的文档, 标签列表以类似”__label__sauce __label__cheese”的形式展现, 代表有两个标签sauce和cheese, 所有标签__label__均以前缀开头，这是fastText识别标签或单词的方式. 标签之后的一段话就是文本信息.如: How much does potato starch affect a cheese sauce recipe?</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h4 id="第二步-训练集与验证集的划分"><a href="#第二步-训练集与验证集的划分" class="headerlink" title="第二步: 训练集与验证集的划分"></a>第二步: 训练集与验证集的划分</h4><pre class="line-numbers language-none"><code class="language-none"># 查看数据总数
$ wc cooking.stackexchange.txt <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<pre class="line-numbers language-none"><code class="language-none">15404  169582 1401900 cooking.stackexchange.txt <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<pre class="line-numbers language-none"><code class="language-none"># 12404条数据作为训练数据
$ head -n 12404 cooking.stackexchange.txt &gt; cooking.train
# 3000条数据作为验证数据
$ tail -n 3000 cooking.stackexchange.txt &gt; cooking.valid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第三步-训练模型"><a href="#第三步-训练模型" class="headerlink" title="第三步: 训练模型"></a>第三步: 训练模型</h4><pre class="line-numbers language-none"><code class="language-none"># 代码运行在python解释器中
# 导入fasttext
&gt;&gt;&gt; import fasttext
# 使用fasttext的train_supervised方法进行文本分类模型的训练
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train")

# 获得结果
Read 0M words
# 不重复的词汇总数
Number of words:  14543
# 标签总数
Number of labels: 735
# Progress: 训练进度, 因为我们这里显示的是最后的训练完成信息, 所以进度是100%
# words/sec/thread: 每个线程每秒处理的平均词汇数
# lr: 当前的学习率, 因为训练完成所以学习率是0
# avg.loss: 训练过程的平均损失 
# ETA: 预计剩余训练时间, 因为已训练完成所以是0
Progress: 100.0% words/sec/thread:   60162 lr:  0.000000 avg.loss: 10.056812 ETA:   0h 0m 0s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第四步-使用模型进行预测并评估"><a href="#第四步-使用模型进行预测并评估" class="headerlink" title="第四步: 使用模型进行预测并评估"></a>第四步: 使用模型进行预测并评估</h4><pre class="line-numbers language-none"><code class="language-none"># 使用模型预测一段输入文本, 通过我们常识, 可知预测是正确的, 但是对应预测概率并不大
&gt;&gt;&gt; model.predict("Which baking dish is best to bake a banana bread ?")
# 元组中的第一项代表标签, 第二项代表对应的概率
(('__label__baking',), array([0.06550845]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>



<pre class="line-numbers language-none"><code class="language-none"># 通过我们常识可知预测是错误的
&gt;&gt;&gt; model.predict("Why not put knives in the dishwasher?")
(('__label__food-safety',), array([0.07541209]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>



<pre class="line-numbers language-none"><code class="language-none"># 为了评估模型到底表现如何, 我们在3000条的验证集上进行测试
&gt;&gt;&gt; model.test("cooking.valid")
# 元组中的每项分别代表, 验证集样本数量, 精度以及召回率 
# 我们看到模型精度和召回率表现都很差, 接下来我们讲学习如何进行优化.
(3000, 0.124, 0.0541)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第五步-模型调优"><a href="#第五步-模型调优" class="headerlink" title="第五步: 模型调优"></a>第五步: 模型调优</h4><ul>
<li>原始数据处理:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 通过查看数据, 我们发现数据中存在许多标点符号与单词相连以及大小写不统一, 
# 这些因素对我们最终的分类目标没有益处, 反是增加了模型提取分类规律的难度,
# 因此我们选择将它们去除或转化

# 处理前的部分数据
__label__fish Arctic char available in North-America
__label__pasta __label__salt __label__boiling When cooking pasta in salted water how much of the salt is absorbed?
__label__coffee Emergency Coffee via Chocolate Covered Coffee Beans?
__label__cake Non-beet alternatives to standard red food dye
__label__cheese __label__lentils Could cheese "halt" the tenderness of cooking lentils?
__label__asian-cuisine __label__chili-peppers __label__kimchi __label__korean-cuisine What kind of peppers are used in Gochugaru ()?
__label__consistency Pavlova Roll failure
__label__eggs __label__bread What qualities should I be looking for when making the best French Toast?
__label__meat __label__flour __label__stews __label__braising Coating meat in flour before browning, bad idea?
__label__food-safety Raw roast beef on the edge of safe?
__label__pork __label__food-identification How do I determine the cut of a pork steak prior to purchasing it?<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<pre class="line-numbers language-none"><code class="language-none"># 通过服务器终端进行简单的数据预处理
# 使标点符号与单词分离并统一使用小写字母
&gt;&gt; cat cooking.stackexchange.txt | sed -e "s/\([.\!?,'/()]\)/ \1 /g" | tr "[:upper:]" "[:lower:]" &gt; cooking.preprocessed.txt
&gt;&gt; head -n 12404 cooking.preprocessed.txt &gt; cooking.train
&gt;&gt; tail -n 3000 cooking.preprocessed.txt &gt; cooking.valid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<pre class="line-numbers language-none"><code class="language-none"># 处理后的部分数据
__label__fish arctic char available in north-america
__label__pasta __label__salt __label__boiling when cooking pasta in salted water how much of the salt is absorbed ?
__label__coffee emergency coffee via chocolate covered coffee beans ?
__label__cake non-beet alternatives to standard red food dye
__label__cheese __label__lentils could cheese "halt" the tenderness of cooking lentils ?
__label__asian-cuisine __label__chili-peppers __label__kimchi __label__korean-cuisine what kind of peppers are used in gochugaru  (  )  ?
__label__consistency pavlova roll failure
__label__eggs __label__bread what qualities should i be looking for when making the best french toast ?
__label__meat __label__flour __label__stews __label__braising coating meat in flour before browning ,  bad idea ?
__label__food-safety raw roast beef on the edge of safe ?
__label__pork __label__food-identification how do i determine the cut of a pork steak prior to purchasing it ?<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li>数据处理后进行训练并测试:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 重新训练
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train")
Read 0M words

# 不重复的词汇总数减少很多, 因为之前会把带大写字母或者与标点符号相连接的单词都认为是新的单词
Number of words:  8952
Number of labels: 735

# 我们看到平均损失有所下降
Progress: 100.0% words/sec/thread:   65737 lr:  0.000000 avg.loss:  9.966091 ETA:   0h 0m 0s

# 重新测试
&gt;&gt;&gt; model.test("cooking.valid")
# 我们看到精度和召回率都有所提升
(3000, 0.161, 0.06962663975782038)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>增加训练轮数:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 设置train_supervised方法中的参数epoch来增加训练轮数, 默认的轮数是5次
# 增加轮数意味着模型能够有更多机会在有限数据中调整分类规律, 当然这也会增加训练时间
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train", epoch=25)
Read 0M words
Number of words:  8952
Number of labels: 735

# 我们看到平均损失继续下降
Progress: 100.0% words/sec/thread:   66283 lr:  0.000000 avg.loss:  7.203885 ETA:   0h 0m 0s

&gt;&gt;&gt; model.test("cooking.valid")
# 我们看到精度已经提升到了42%, 召回率提升至18%.
(3000, 0.4206666666666667, 0.1819230214790255)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>调整学习率:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 设置train_supervised方法中的参数lr来调整学习率, 默认的学习率大小是0.1
# 增大学习率意味着增大了梯度下降的步长使其在有限的迭代步骤下更接近最优点
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train", lr=1.0, epoch=25)
Read 0M words
Number of words:  8952
Number of labels: 735

# 平均损失继续下降
Progress: 100.0% words/sec/thread:   66027 lr:  0.000000 avg.loss:  4.278283 ETA:   0h 0m 0s

&gt;&gt;&gt; model.test("cooking.valid")
# 我们看到精度已经提升到了47%, 召回率提升至20%.
(3000, 0.47633333333333333, 0.20599682860025947)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>增加n-gram特征:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 设置train_supervised方法中的参数wordNgrams来添加n-gram特征, 默认是1, 也就是没有n-gram特征
# 我们这里将其设置为2意味着添加2-gram特征, 这些特征帮助模型捕捉前后词汇之间的关联, 更好的提取分类规则用于模型分类, 当然这也会增加模型训时练占用的资源和时间.
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train", lr=1.0, epoch=25, wordNgrams=2)
Read 0M words
Number of words:  8952
Number of labels: 735

# 平均损失继续下降
Progress: 100.0% words/sec/thread:   65084 lr:  0.000000 avg.loss:  3.189422 ETA:   0h 0m 0s

&gt;&gt;&gt; model.test("cooking.valid")
# 我们看到精度已经提升到了49%, 召回率提升至21%.
(3000, 0.49233333333333335, 0.2129162462159435)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>修改损失计算方式:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 随着我们不断的添加优化策略, 模型训练速度也越来越慢
# 为了能够提升fasttext模型的训练效率, 减小训练时间
# 设置train_supervised方法中的参数loss来修改损失计算方式(等效于输出层的结构), 默认是softmax层结构
# 我们这里将其设置为'hs', 代表层次softmax结构, 意味着输出层的结构(计算方式)发生了变化, 将以一种更低复杂度的方式来计算损失.
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train", lr=1.0, epoch=25, wordNgrams=2, loss='hs')
Read 0M words
Number of words:  8952
Number of labels: 735
Progress: 100.0% words/sec/thread: 1341740 lr:  0.000000 avg.loss:  2.225962 ETA:   0h 0m 0s
&gt;&gt;&gt; model.test("cooking.valid")
# 我们看到精度和召回率稍有波动, 但训练时间却缩短到仅仅几秒
(3000, 0.483, 0.20887991927346114)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>自动超参数调优:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 手动调节和寻找超参数是非常困难的, 因为参数之间可能相关, 并且不同数据集需要的超参数也不同, 
# 因此可以使用fasttext的autotuneValidationFile参数进行自动超参数调优.
# autotuneValidationFile参数需要指定验证数据集所在路径, 它将在验证集上使用随机搜索方法寻找可能最优的超参数.
# 使用autotuneDuration参数可以控制随机搜索的时间, 默认是300s, 根据不同的需求, 我们可以延长或缩短时间.
# 验证集路径'cooking.valid', 随机搜索600秒
&gt;&gt;&gt; model = fasttext.train_supervised(input='cooking.train', autotuneValidationFile='cooking.valid', autotuneDuration=600)

Progress: 100.0% Trials:   38 Best score:  0.376170 ETA:   0h 0m 0s
Training again with best arguments
Read 0M words
Number of words:  8952
Number of labels: 735
Progress: 100.0% words/sec/thread:   63791 lr:  0.000000 avg.loss:  1.888165 ETA:   0h 0m 0s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>实际生产中多标签多分类问题的损失计算方式:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 针对多标签多分类问题, 使用'softmax'或者'hs'有时并不是最佳选择, 因为我们最终得到的应该是多个标签, 而softmax却只能最大化一个标签. 
# 所以我们往往会选择为每个标签使用独立的二分类器作为输出层结构, 
# 对应的损失计算方式为'ova'表示one vs all.
# 这种输出层的改变意味着我们在统一语料下同时训练多个二分类模型,
# 对于二分类模型来讲, lr不宜过大, 这里我们设置为0.2
&gt;&gt;&gt; model = fasttext.train_supervised(input="cooking.train", lr=0.2, epoch=25, wordNgrams=2, loss='ova')
Read 0M words
Number of words:  8952
Number of labels: 735
Progress: 100.0% words/sec/thread:   65044 lr:  0.000000 avg.loss:  7.713312 ETA:   0h 0m 0s 

# 我们使用模型进行单条样本的预测, 来看一下它的输出结果.
# 参数k代表指定模型输出多少个标签, 默认为1, 这里设置为-1, 意味着尽可能多的输出.
# 参数threshold代表显示的标签概率阈值, 设置为0.5, 意味着显示概率大于0.5的标签
&gt;&gt;&gt; model.predict("Which baking dish is best to bake a banana bread ?", k=-1, threshold=0.5)

# 我看到根据输入文本, 输出了它的三个最有可能的标签
((u'__label__baking', u'__label__bananas', u'__label__bread'), array([1.00000, 0.939923, 0.592677]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第六步-模型保存与重加载"><a href="#第六步-模型保存与重加载" class="headerlink" title="第六步: 模型保存与重加载"></a>第六步: 模型保存与重加载</h4><pre class="line-numbers language-none"><code class="language-none"># 使用model的save_model方法保存模型到指定目录
# 你可以在指定目录下找到model_cooking.bin文件
&gt;&gt;&gt; model.save_model("./model_cooking.bin")

# 使用fasttext的load_model进行模型的重加载
&gt;&gt;&gt; model = fasttext.load_model("./model_cooking.bin")

# 重加载后的模型使用方法和之前完全相同
&gt;&gt;&gt; model.predict("Which baking dish is best to bake a banana bread ?", k=-1, threshold=0.5)
((u'__label__baking', u'__label__bananas', u'__label__bread'), array([1.00000, 0.939923, 0.592677]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="小节总结"><a href="#小节总结" class="headerlink" title="小节总结"></a>小节总结</h3><ul>
<li><p>学习了什么是文本分类:</p>
<ul>
<li>文本分类的是将文档（例如电子邮件，帖子，文本消息，产品评论等）分配给一个或多个类别. 当今文本分类的实现多是使用机器学习方法从训练数据中提取分类规则以进行分类, 因此构建文本分类器需要带标签的数据.</li>
</ul>
<hr>
</li>
<li><p>文本分类的种类:</p>
<ul>
<li>二分类:<ul>
<li>文本被分类两个类别中, 往往这两个类别是对立面, 比如: 判断一句评论是好评还是差评.</li>
</ul>
</li>
<li>单标签多分类:<ul>
<li>文本被分入到多个类别中, 且每条文本只能属于某一个类别(即被打上某一个标签), 比如: 输入一个人名, 判断它是来自哪个国家的人名.</li>
</ul>
</li>
<li>多标签多分类:<ul>
<li>文本被分人到多个类别中, 但每条文本可以属于多个类别(即被打上多个标签), 比如: 输入一段描述, 判断可能是和哪些兴趣爱好有关, 一段描述中可能即讨论了美食, 又太讨论了游戏爱好.</li>
</ul>
</li>
</ul>
<hr>
</li>
<li><p>使用fasttext工具进行文本分类的过程:</p>
<ul>
<li>第一步: 获取数据</li>
<li>第二步: 训练集与验证集的划分</li>
<li>第三步: 训练模型</li>
<li>第四步: 使用模型进行预测并评估</li>
<li>第五步: 模型调优</li>
<li>第六步: 模型保存与重加载</li>
</ul>
</li>
</ul>
<hr>
<h2 id="1-3-训练词向量"><a href="#1-3-训练词向量" class="headerlink" title="1.3 训练词向量"></a>1.3 训练词向量</h2><hr>
<h3 id="学习目标-2"><a href="#学习目标-2" class="headerlink" title="学习目标"></a>学习目标</h3><ul>
<li>了解词向量的相关知识.</li>
<li>掌握fasttext工具训练词向量的过程.</li>
</ul>
<hr>
<ul>
<li>词向量的相关知识:<ul>
<li>用向量表示文本中的词汇(或字符)是现代机器学习中最流行的做法, 这些向量能够很好的捕捉语言之间的关系, 从而提升基于词向量的各种NLP任务的效果.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="使用fasttext工具训练词向量的过程"><a href="#使用fasttext工具训练词向量的过程" class="headerlink" title="使用fasttext工具训练词向量的过程"></a>使用fasttext工具训练词向量的过程</h3><ul>
<li>第一步: 获取数据</li>
<li>第二步: 训练词向量</li>
<li>第三步: 模型超参数设定</li>
<li>第四步: 模型效果检验</li>
<li>第五步: 模型的保存与重加载</li>
</ul>
<hr>
<h4 id="第一步-获取数据-1"><a href="#第一步-获取数据-1" class="headerlink" title="第一步: 获取数据"></a>第一步: 获取数据</h4><pre class="line-numbers language-none"><code class="language-none"># 在这里, 我们将研究英语维基百科的部分网页信息, 它的大小在300M左右
# 这些语料已经被准备好, 我们可以通过Matt Mahoney的网站下载.
# 首先创建一个存储数据的文件夹data
$ mkdir data
# 使用wget下载数据的zip压缩包, 它将存储在data目录中
$ wget -c http://mattmahoney.net/dc/enwik9.zip -P data
# 使用unzip解压, 如果你的服务器中还没有unzip命令, 请使用: yum install unzip -y
# 解压后在data目录下会出现enwik9的文件夹
$ unzip data/enwik9.zip -d data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>查看原始数据:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none">$ head -10 data/enwik9

# 原始数据将输出很多包含XML/HTML格式的内容, 这些内容并不是我们需要的
&lt;mediawiki xmlns="http://www.mediawiki.org/xml/export-0.3/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.3/ http://www.mediawiki.org/xml/export-0.3.xsd" version="0.3" xml:lang="en"&gt;
  &lt;siteinfo&gt;
    &lt;sitename&gt;Wikipedia&lt;/sitename&gt;
    &lt;base&gt;http://en.wikipedia.org/wiki/Main_Page&lt;/base&gt;
    &lt;generator&gt;MediaWiki 1.6alpha&lt;/generator&gt;
    &lt;case&gt;first-letter&lt;/case&gt;
      &lt;namespaces&gt;
      &lt;namespace key="-2"&gt;Media&lt;/namespace&gt;
      &lt;namespace key="-1"&gt;Special&lt;/namespace&gt;
      &lt;namespace key="0" /&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>原始数据处理:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 使用wikifil.pl文件处理脚本来清除XML/HTML格式的内容
# 注: wikifil.pl文件已为大家提供
$ perl wikifil.pl data/enwik9 &gt; data/fil9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>查看预处理后的数据:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 查看前80个字符
head -c 80 data/fil9

# 输出结果为由空格分割的单词
 anarchism originated as a term of abuse first used against early working class<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第二步-训练词向量"><a href="#第二步-训练词向量" class="headerlink" title="第二步: 训练词向量"></a>第二步: 训练词向量</h4><pre class="line-numbers language-none"><code class="language-none"># 代码运行在python解释器中
# 导入fasttext
&gt;&gt;&gt; import fasttext
# 使用fasttext的train_unsupervised(无监督训练方法)进行词向量的训练
# 它的参数是数据集的持久化文件路径'data/fil9'
&gt;&gt;&gt; model = fasttext.train_unsupervised('data/fil9')


# 有效训练词汇量为124M, 共218316个单词
Read 124M words
Number of words:  218316
Number of labels: 0
Progress: 100.0% words/sec/thread:   53996 lr:  0.000000 loss:  0.734999 ETA:   0h 0m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<ul>
<li>查看单词对应的词向量:</li>
</ul>
<pre class="line-numbers language-none"><code class="language-none"># 通过get_word_vector方法来获得指定词汇的词向量
&gt;&gt;&gt; model.get_word_vector("the")

array([-0.03087516,  0.09221972,  0.17660329,  0.17308897,  0.12863874,
        0.13912526, -0.09851588,  0.00739991,  0.37038437, -0.00845221,
        ...
       -0.21184735, -0.05048715, -0.34571868,  0.23765688,  0.23726143],
      dtype=float32)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第三步-模型超参数设定"><a href="#第三步-模型超参数设定" class="headerlink" title="第三步: 模型超参数设定"></a>第三步: 模型超参数设定</h4><pre class="line-numbers language-none"><code class="language-none"># 在训练词向量过程中, 我们可以设定很多常用超参数来调节我们的模型效果, 如:
# 无监督训练模式: 'skipgram' 或者 'cbow', 默认为'skipgram', 在实践中，skipgram模式在利用子词方面比cbow更好.
# 词嵌入维度dim: 默认为100, 但随着语料库的增大, 词嵌入的维度往往也要更大.
# 数据循环次数epoch: 默认为5, 但当你的数据集足够大, 可能不需要那么多次.
# 学习率lr: 默认为0.05, 根据经验, 建议选择[0.01，1]范围内.
# 使用的线程数thread: 默认为12个线程, 一般建议和你的cpu核数相同.

&gt;&gt;&gt; model = fasttext.train_unsupervised('data/fil9', "cbow", dim=300, epoch=1, lr=0.1, thread=8)

Read 124M words
Number of words:  218316
Number of labels: 0
Progress: 100.0% words/sec/thread:   49523 lr:  0.000000 avg.loss:  1.777205 ETA:   0h 0m 0s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第四步-模型效果检验"><a href="#第四步-模型效果检验" class="headerlink" title="第四步: 模型效果检验"></a>第四步: 模型效果检验</h4><pre class="line-numbers language-none"><code class="language-none"># 检查单词向量质量的一种简单方法就是查看其邻近单词, 通过我们主观来判断这些邻近单词是否与目标单词相关来粗略评定模型效果好坏.

# 查找"运动"的邻近单词, 我们可以发现"体育网", "运动汽车", "运动服"等. 
&gt;&gt;&gt; model.get_nearest_neighbors('sports')

[(0.8414610624313354, 'sportsnet'), (0.8134572505950928, 'sport'), (0.8100415468215942, 'sportscars'), (0.8021156787872314, 'sportsground'), (0.7889881134033203, 'sportswomen'), (0.7863013744354248, 'sportsplex'), (0.7786710262298584, 'sporty'), (0.7696356177330017, 'sportscar'), (0.7619683146476746, 'sportswear'), (0.7600985765457153, 'sportin')]


# 查找"音乐"的邻近单词, 我们可以发现与音乐有关的词汇.
&gt;&gt;&gt; model.get_nearest_neighbors('music')

[(0.8908010125160217, 'emusic'), (0.8464668393135071, 'musicmoz'), (0.8444250822067261, 'musics'), (0.8113634586334229, 'allmusic'), (0.8106718063354492, 'musices'), (0.8049437999725342, 'musicam'), (0.8004694581031799, 'musicom'), (0.7952923774719238, 'muchmusic'), (0.7852965593338013, 'musicweb'), (0.7767147421836853, 'musico')]

# 查找"小狗"的邻近单词, 我们可以发现与小狗有关的词汇.
&gt;&gt;&gt; model.get_nearest_neighbors('dog')

[(0.8456876873970032, 'catdog'), (0.7480780482292175, 'dogcow'), (0.7289096117019653, 'sleddog'), (0.7269964218139648, 'hotdog'), (0.7114801406860352, 'sheepdog'), (0.6947550773620605, 'dogo'), (0.6897546648979187, 'bodog'), (0.6621081829071045, 'maddog'), (0.6605004072189331, 'dogs'), (0.6398137211799622, 'dogpile')]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第五步-模型的保存与重加载"><a href="#第五步-模型的保存与重加载" class="headerlink" title="第五步: 模型的保存与重加载"></a>第五步: 模型的保存与重加载</h4><pre class="line-numbers language-none"><code class="language-none"># 使用save_model保存模型
&gt;&gt;&gt; model.save_model("fil9.bin")

# 使用fasttext.load_model加载模型
&gt;&gt;&gt; model = fasttext.load_model("fil9.bin")
&gt;&gt;&gt; model.get_word_vector("the")

array([-0.03087516,  0.09221972,  0.17660329,  0.17308897,  0.12863874,
        0.13912526, -0.09851588,  0.00739991,  0.37038437, -0.00845221,
        ...
       -0.21184735, -0.05048715, -0.34571868,  0.23765688,  0.23726143],
      dtype=float32)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="小节总结-1"><a href="#小节总结-1" class="headerlink" title="小节总结"></a>小节总结</h3><ul>
<li><p>学习了词向量的相关知识:</p>
<ul>
<li>用向量表示文本中的词汇(或字符)是现代机器学习中最流行的做法, 这些向量能够很好的捕捉语言之间的关系, 从而提升基于词向量的各种NLP任务的效果.</li>
</ul>
<hr>
</li>
<li><p>使用fasttext工具训练词向量的过程:</p>
<ul>
<li>第一步: 获取数据</li>
<li>第二步: 训练词向量</li>
<li>第三步: 模型超参数设定</li>
<li>第四步: 模型效果检验</li>
<li>第五步: 模型的保存与重加载</li>
</ul>
</li>
</ul>
<hr>
<h2 id="1-4-词向量迁移"><a href="#1-4-词向量迁移" class="headerlink" title="1.4 词向量迁移"></a>1.4 词向量迁移</h2><hr>
<h3 id="学习目标-3"><a href="#学习目标-3" class="headerlink" title="学习目标"></a>学习目标</h3><ul>
<li>了解什么是词向量迁移.</li>
<li>了解fasttext工具中有哪些可迁移的词向量模型.</li>
<li>掌握如何使用fasttext进行词向量模型迁移.</li>
</ul>
<hr>
<ul>
<li>什么是词向量迁移:<ul>
<li>使用在大型语料库上已经进行训练完成的词向量模型.</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>fasttext工具中可以提供的可迁移的词向量:<ul>
<li>fasttext提供了157种语言的在CommonCrawl和Wikipedia语料上进行训练的可迁移词向量模型, 它们采用CBOW模式进行训练, 词向量维度为300维. 可通过该地址查看具体语言词向量模型: <a target="_blank" rel="noopener" href="https://fasttext.cc/docs/en/crawl-vectors.html">https://fasttext.cc/docs/en/crawl-vectors.html</a></li>
<li>fasttext提供了294种语言的在Wikipedia语料上进行训练的可迁移词向量模型, 它们采用skipgram模式进行训练, 词向量维度同样是300维. 可通过该地址查看具体语言词向量模型: <a target="_blank" rel="noopener" href="https://fasttext.cc/docs/en/pretrained-vectors.html">https://fasttext.cc/docs/en/pretrained-vectors.html</a></li>
</ul>
</li>
</ul>
<hr>
<h3 id="如何使用fasttext进行词向量模型迁移"><a href="#如何使用fasttext进行词向量模型迁移" class="headerlink" title="如何使用fasttext进行词向量模型迁移"></a>如何使用fasttext进行词向量模型迁移</h3><ul>
<li>第一步: 下载词向量模型压缩的bin.gz文件</li>
<li>第二步: 解压bin.gz文件到bin文件</li>
<li>第三步: 加载bin文件获取词向量</li>
<li>第四步: 利用邻近词进行效果检验</li>
</ul>
<hr>
<h4 id="第一步-下载词向量模型压缩的bin-gz文件"><a href="#第一步-下载词向量模型压缩的bin-gz文件" class="headerlink" title="第一步: 下载词向量模型压缩的bin.gz文件"></a>第一步: 下载词向量模型压缩的bin.gz文件</h4><pre class="line-numbers language-none"><code class="language-none"># 这里我们以迁移在CommonCrawl和Wikipedia语料上进行训练的中文词向量模型为例:
# 下载中文词向量模型(bin.gz文件)
wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.zh.300.bin.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第二步-解压bin-gz文件到bin文件"><a href="#第二步-解压bin-gz文件到bin文件" class="headerlink" title="第二步: 解压bin.gz文件到bin文件"></a>第二步: 解压bin.gz文件到bin文件</h4><pre class="line-numbers language-none"><code class="language-none"># 使用gunzip进行解压, 获取cc.zh.300.bin文件
gunzip cc.zh.300.bin.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<hr>
<h4 id="第三步-加载bin文件获取词向量"><a href="#第三步-加载bin文件获取词向量" class="headerlink" title="第三步: 加载bin文件获取词向量"></a>第三步: 加载bin文件获取词向量</h4><pre class="line-numbers language-none"><code class="language-none"># 加载模型
&gt;&gt;&gt; model = fasttext.load_model("cc.zh.300.bin")

# 查看前100个词汇(这里的词汇是广义的, 可以是中文符号或汉字))
&gt;&gt;&gt; model.words[:100]
['，', '的', '。', '&lt;/s&gt;', '、', '是', '一', '在', '：', '了', '（', '）', "'", '和', '不', '有', '我', ',', ')', '(', '“', '”', '也', '人', '个', ':', '中', '.', '就', '他', '》', '《', '-', '你', '都', '上', '大', '！', '这', '为', '多', '与', '章', '「', '到', '」', '要', '？', '被', '而', '能', '等', '可以', '年', '；', '|', '以', '及', '之', '公司', '对', '中国', '很', '会', '小', '但', '我们', '最', '更', '/', '1', '三', '新', '自己', '可', '2', '或', '次', '好', '将', '第', '种', '她', '…', '3', '地', '對', '用', '工作', '下', '后', '由', '两', '使用', '还', '又', '您', '?', '其', '已']


# 使用模型获得'音乐'这个名词的词向量
&gt;&gt;&gt; model.get_word_vector("音乐")
array([-6.81843981e-02,  3.84048335e-02,  4.63239700e-01,  6.11658543e-02,
        9.38086119e-03, -9.63955745e-02,  1.28141120e-01, -6.51574507e-02,
        ...
        3.13430429e-02, -6.43611327e-02,  1.68979481e-01, -1.95011273e-01],
      dtype=float32)    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h4 id="第四步-利用邻近词进行效果检验"><a href="#第四步-利用邻近词进行效果检验" class="headerlink" title="第四步: 利用邻近词进行效果检验"></a>第四步: 利用邻近词进行效果检验</h4><pre class="line-numbers language-none"><code class="language-none"># 以'音乐'为例, 返回的邻近词基本上与音乐都有关系, 如乐曲, 音乐会, 声乐等.
&gt;&gt;&gt; model.get_nearest_neighbors("音乐")
[(0.6703276634216309, '乐曲'), (0.6569967269897461, '音乐人'), (0.6565821170806885, '声乐'), (0.6557438373565674, '轻音乐'), (0.6536258459091187, '音乐家'), (0.6502416133880615, '配乐'), (0.6501686573028564, '艺术'), (0.6437276005744934, '音乐会'), (0.639589250087738, '原声'), (0.6368917226791382, '音响')]


# 以'美术'为例, 返回的邻近词基本上与美术都有关系, 如艺术, 绘画, 霍廷霄(满城尽带黄金甲的美术师)等.
&gt;&gt;&gt; model.get_nearest_neighbors("美术")
[(0.724744975566864, '艺术'), (0.7165924310684204, '绘画'), (0.6741853356361389, '霍廷霄'), (0.6470299363136292, '纯艺'), (0.6335071921348572, '美术家'), (0.6304370164871216, '美院'), (0.624431312084198, '艺术类'), (0.6244068741798401, '陈浩忠'), (0.62302166223526, '美术史'), (0.621710479259491, '环艺系')]


# 以'周杰伦'为例, 返回的邻近词基本上与明星有关系, 如杰伦, 周董, 陈奕迅等.
&gt;&gt;&gt; model.get_nearest_neighbors("周杰伦")
[(0.6995140910148621, '杰伦'), (0.6967097520828247, '周杰倫'), (0.6859776377677917, '周董'), (0.6381043195724487, '陈奕迅'), (0.6367626190185547, '张靓颖'), (0.6313326358795166, '张韶涵'), (0.6271176338195801, '谢霆锋'), (0.6188404560089111, '周华健'), (0.6184280514717102, '林俊杰'), (0.6143589019775391, '王力宏')]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="小节总结-2"><a href="#小节总结-2" class="headerlink" title="小节总结"></a>小节总结</h3><ul>
<li><p>学习了什么是词向量迁移:</p>
<ul>
<li>使用在大型语料库上已经进行训练完成的词向量模型.</li>
</ul>
<hr>
</li>
<li><p>学习了fasttext工具中可以提供的可迁移的词向量:</p>
<ul>
<li>fasttext提供了157种语言的在CommonCrawl和Wikipedia语料上进行训练的可迁移词向量模型, 它们采用CBOW模式进行训练, 词向量维度为300维. 可通过该地址查看具体语言词向量模型: <a target="_blank" rel="noopener" href="https://fasttext.cc/docs/en/crawl-vectors.html">https://fasttext.cc/docs/en/crawl-vectors.html</a></li>
<li>fasttext提供了294种语言的在Wikipedia语料上进行训练的可迁移词向量模型, 它们采用skipgram模式进行训练, 词向量维度同样是300维. 可通过该地址查看具体语言词向量模型: <a target="_blank" rel="noopener" href="https://fasttext.cc/docs/en/pretrained-vectors.html">https://fasttext.cc/docs/en/pretrained-vectors.html</a></li>
</ul>
<hr>
</li>
<li><p>如何使用fasttext进行词向量模型迁移:</p>
<ul>
<li>第一步: 下载词向量模型压缩的bin.gz文件</li>
<li>第二步: 解压bin.gz文件到bin文件</li>
<li>第三步: 加载bin文件获取词向量</li>
<li>第四步: 利用邻近词进行效果检验</li>
</ul>
</li>
</ul>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>


            

    <div class="reprint" id="reprint-statement">
        <p class="reprint-tip">
            <i class="fa fa-exclamation-triangle"></i>&nbsp;&nbsp;
            <span>版权声明</span>
        </p>
        
            <div class="center-align">
                <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                    <img alt=""
                         style="border-width:0"
                         src="https://i.creativecommons.org/l/by/4.0/88x31.png"/>
                </a>
            </div>
            <br/>
            <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text"
                  property="dct:title" rel="dct:type">
                    《fasttext使用教程》
                </span> by
            <a xmlns:cc="http://creativecommons.org/ns#" href="/2021/04/23/fasttext-shi-yong-jiao-cheng/" property="cc:attributionName"
               rel="cc:attributionURL">
                浩
            </a> under
            <a rel="license noopener" target="_blank" href="https://creativecommons.org/licenses/by/4.0/deed.zh">
                CC BY 4.0
            </a>许可协议。转载请注明来源
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>


        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '40e1f34538c8ad91cb4f',
        clientSecret: '822505a3f5d515e796ae5d0f00e3cc48b03403cd',
        repo: 'x-hao.github.io',
        owner: 'x-hao',
        admin: ["浩"],
        id: '2021-04-23T15-36-10',
        distractionFreeMode: false,  // Facebook-like distraction free mode
        proxy: 'https://netnr-proxy.cloudno.de/https://github.com/login/oauth/access_token'
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/04/23/bert-transformer-mo-xing-jia-gou-yu-xiang-jie/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="BERT,Transformer模型架构与详解">
                        
                        <span class="card-title">BERT,Transformer模型架构与详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1. BERT,Transformer的模型架构与详解1.1 认识BERT
学习目标
了解什么是BERT.
掌握BERT的架构.
掌握BERT的预训练任务.


什么是BERT
BERT是2018年10月由Google AI研究院提出的一种
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2021-04-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/nlp/" class="post-category" target="_blank">
                                    nlp
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/nlp/" target="_blank">
                        <span class="chip bg-color">nlp</span>
                    </a>
                    
                    <a href="/tags/Transformer/" target="_blank">
                        <span class="chip bg-color">Transformer</span>
                    </a>
                    
                    <a href="/tags/BERT/" target="_blank">
                        <span class="chip bg-color">BERT</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/04/23/fasttext-qian-yi-xue-xi/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/21.jpg" class="responsive-img" alt="fasttext迁移学习">
                        
                        <span class="card-title">fasttext迁移学习</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            2.1 迁移学习理论
学习目标
了解迁移学习中的有关概念.
掌握迁移学习的两种迁移方式.



迁移学习中的有关概念:
预训练模型
微调
微调脚本





预训练模型(Pretrained model):
一般情况下预训练模型都是大型模型
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2021-04-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/nlp/" class="post-category" target="_blank">
                                    nlp
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/nlp/" target="_blank">
                        <span class="chip bg-color">nlp</span>
                    </a>
                    
                    <a href="/tags/fasttext/" target="_blank">
                        <span class="chip bg-color">fasttext</span>
                    </a>
                    
                    <a href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" target="_blank">
                        <span class="chip bg-color">迁移学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 浩的博客<br />'
            + '文章作者: 浩<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>

<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

    <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&nbsp;&copy;<a href="http://example.com" target="_blank">浩</a>&nbsp;基于
            <a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>&nbsp;主题搭建
            <br>
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="fa fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fa fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            <br>
            <span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
            <script>
                var now = new Date();

                function createtime() {
                    var grt = new Date("06/28/2019 00:00:00");
                    now.setTime(now.getTime() + 250);
                    days = (now - grt) / 1000 / 60 / 60 / 24;
                    dnum = Math.floor(days);
                    hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum);
                    hnum = Math.floor(hours);
                    if (String(hnum).length == 1) {
                        hnum = "0" + hnum;
                    }
                    minutes = (now - grt) / 1000 / 60 - (24 * 60 * dnum) - (60 * hnum);
                    mnum = Math.floor(minutes);
                    if (String(mnum).length == 1) {
                        mnum = "0" + mnum;
                    }
                    seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
                    snum = Math.round(seconds);
                    if (String(snum).length == 1) {
                        snum = "0" + snum;
                    }
                    document.getElementById("timeDate").innerHTML = "本站已安全运行 " + dnum + " 天 ";
                    document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
                }
                setInterval("createtime()", 250);
            </script>
            
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">














    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', '');
</script>


    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- 在线聊天工具  洪卫 shw2018 modify 2019.09.17 -->
    


    
    <script>
        (function (i, s, o, g, r, a, m) {
            i["DaoVoiceObject"] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            a.charset = "utf-8";
            m.parentNode.insertBefore(a, m)
        })(window, document, "script", ('https:' == document.location.protocol ? 'https:' : 'http:') +
            "//widget.daovoice.io/widget/6984b559.js", "daovoice")
        daovoice('init', {
            app_id: ""
        });
        daovoice('update');
    </script>
    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

</body>

</html>